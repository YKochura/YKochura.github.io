<h2 style="text-align: center;"> Research </h2>
<div class="iframe-box" style="margin-top: 0px">
<iframe class="iframe" src="https://docs.google.com/presentation/d/e/2PACX-1vSj1GlDHEk8AhlYSL9eRb0sFHDF-QqvgS9SckgeekmzTtYdNQWGalhOR5MlmfKsgyW3TtOYq-SpyPkA/embed"
        frameborder="0" width="100%" height="auto" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
</div>

<!--<table>-->
<!--    <tr>-->
<!--        <th>-->
<!--            <strong style="font-size:21px;"> interpretable ml </strong> <br/>-->
<!--            <a href="/blog/research/interp"> what is interpretability? </a> <br/>-->
<!--            <a href="/blog/research/interp_eval"> evaluating interpretability </a>-->
<!--        </th>-->
<!--&lt;!&ndash;        <th><strong style="font-size:21px;"> interpretability applications </strong></th>&ndash;&gt;-->
<!--        <th>-->
<!--            <strong style="font-size:21px;"> science </strong> <br/>-->
<!--            <a href="/blog/research/connectomics"> Connectomics</a> <br/>-->
<!--            <a href="/blog/research/neural_coding" > neural coding </a>-->
<!--        </th>-->
<!--&lt;!&ndash;        <th>&ndash;&gt;-->
<!--&lt;!&ndash;            <strong style="font-size:21px;"> ml theory </strong>&ndash;&gt;-->
<!--&lt;!&ndash;        </th>&ndash;&gt;-->
<!--    </tr>-->
<!--    <tr>-->
<!--        <th><br/></th>-->
<!--    </tr>-->
<!--    <tr>-->
<!--        <th><img src="{{ site.baseurl }}/assets/img/alexnet.png" class="research_thumb"></th>-->
<!--&lt;!&ndash;        <th><img src="{{ site.baseurl }}/assets/img/cosmo.png" class="research_thumb"></th>&ndash;&gt;-->
<!--        <th><img src="{{ site.baseurl }}/assets/img/neuron.gif" class="research_thumb"></th>-->
<!--&lt;!&ndash;        <th><img src="{{ site.baseurl }}/assets/img/complexity.png" class="research_thumb"></th>&ndash;&gt;-->
<!--    </tr>-->
<!--</table>-->

<br/>
<br/>

<table id="example" class="display" style="width:100%">
    <thead>
        <tr>
            <th>year</th>
            <th>title</th>
            <th>authors</th>
            <th>tags</th>
            <th>paper</th>
            <th>code</th>
            <th>slides</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>2020</td>
            <td>Revisiting complexity and the bias-variance tradeoff</td>
            <td>dwivedi*, singh*, yu, and wainwright</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/2006.10189">arxiv</a></td>
            <td><a href="https://github.com/csinva/mdl-complexity"><i class="fa fa-github fa-fw"></i></a></td>
            <td>--</td>
        </tr>
        <tr>
            <td>2020</td>
            <td>Curating a COVID-19 data repository and forecasting county-level death counts in the United States</td>
            <td>altieri et al.</td>
            <td>data science</td>
            <td><a href="https://arxiv.org/abs/2005.07882">hdsr</a></td>
            <td><a href="https://github.com/Yu-Group/covid19-severity-prediction"><i class="fa fa-github fa-fw"></i></a></td>
            <td>
                <a href="https://docs.google.com/presentation/d/1J12UX8RS2cia3HkxpmTG9pBdoJR2OZgeDKF-jnht7QU/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a>
            <a href="https://covidseverity.com/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td>2020</td>
            <td>interpretations are useful: penalizing explanations to align neural networks with prior knowledge</td>
            <td>rieger, singh, murdoch & yu</td>
            <td>ml</td>
            <td><a href="https://proceedings.icml.cc/static/paper_files/icml/2020/992-Paper.pdf">icml</a></td>
            <td><a href="https://github.com/laura-rieger/deep-explanation-penalization"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="https://icml.cc/virtual/2020/poster/5914"><i class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td>2020</td>
            <td>transformation importance with applications to cosmology</td>
            <td>singh*, ha*, lanusse, boehm, liu & yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/2003.01926">iclr workshop (spotlight)</a></td>
            <td><a href="https://github.com/csinva/transformation-importance"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="https://docs.google.com/presentation/d/1mH1uG38qJg-ar0G-LiVPZWNKPO_2GiD-uayWM5AI-bo/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td>2019</td>
            <td>disentangled attribution curves for interpreting random forests and boosted trees</td>
            <td>devlin, singh, murdoch & yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/1905.07631">arxiv</a></td>
            <td><a href="https://github.com/csinva/disentangled_attribution_curves"><i class="fa fa-github fa-fw"></i></a></td>
            <td>--</td>
        </tr>
        <tr>
            <td>2019</td>
            <td>interpretable machine learning: definitions, methods, and applications</td>
            <td>Murdoch*, Singh*, Kumbier, Abbasi-Asl, & Yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/1901.04592">pnas</a></td>
            <td>--</td>
            <td><a href="https://docs.google.com/presentation/d/13jbgFyYSSDaMUd2w4RY9GHteTcWJj1drS6_2sOkvnv4/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a>, <a href="{{site.baseurl}}/assets/write_ups/utokyo_19_interp_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
        <tr>
            <td>2019</td>
            <td>hierarchical interpretations for neural network predictions</td>
            <td>Singh*, Murdoch*, & Yu</td>
            <td>ml</td>
            <td><a href="https://arxiv.org/abs/1806.05337">ICLR</a></td>
            <td><a href="https://github.com/csinva/acd"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="https://docs.google.com/presentation/d/1I6djTqVn6YGKqxvQk59-4C39LbE68mNQbX1Go5pzTH4/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a>, <a href="{{site.baseurl}}/assets/write_ups/acd_18_bairday_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
        <tr>
            <td>2018</td>
            <td>large scale image segmentation with structured loss based deep learning for connectome reconstruction</td>
            <td>Funke*, Tschopp*, Grisaitis, Sheridan, Singh, Saalfeld, & Turaga</td>
            <td>ml, neuro</td>
            <td><a href="https://ieeexplore.ieee.org/abstract/document/8364622/">TPAMI</a></td>
            <td><a href="https://github.com/funkey/mala"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="{{site.baseurl}}/assets/write_ups/singh_15_rf_segmentation.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
       <tr>
            <td>2018</td>
            <td>linearization of excitatory synaptic integration at no extra cost</td>
            <td>Morel, Singh, & Levy</td>
            <td>neuro</td>
            <td><a href="http://rdcu.be/FDUo">J Comp Neuro</a></td>
           <td><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i class="fa fa-github fa-fw"></i></a></td>
           <td><a href="https://docs.google.com/presentation/d/1JriXXofysuXyfU4CeyNHJUTYSfa18R9Q3EhkCwFwh4g/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
       <tr>
            <td>2017</td>
            <td>a consensus layer V pyramidal neuron can sustain interpulse-interval coding</td>
            <td>Singh & Levy</td>
            <td>neuro</td>
            <td><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0180839">Plos One</a></td>
            <td><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i class="fa fa-github fa-fw"></i></a></td>
            <td><a href="https://docs.google.com/presentation/d/1JriXXofysuXyfU4CeyNHJUTYSfa18R9Q3EhkCwFwh4g/present?slide=id.p"><i class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
       <tr>
            <td>2017</td>
            <td>a constrained, weighted-l1 minimization approach for joint discovery of heterogeneous neural connectivity graphs</td>
            <td>Singh, Wang, & Qi</td>
            <td>ml, neuro</td>
            <td><a href="https://arxiv.org/abs/1709.04090">neurips Workshop</a></td>
           <td><a href="https://cran.r-project.org/web/packages/simule/index.html"><i class="fa fa-github fa-fw"></i></a></td>
           <td><a href="https://docs.google.com/presentation/d/1GO6lN5o2idozOUdnObXGnXKFbZiJiKKKkmx73uE4BAI/present?slide=id.p4"><i class="fa fa-desktop fa-fw"></i></a>, <a href="{{site.baseurl}}/assets/write_ups/wsimule_17_nips_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a></td>
        </tr>
    </tbody>

</table>

<style>

</style>
